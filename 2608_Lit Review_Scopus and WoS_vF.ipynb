{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62634e2a-f6a8-49e6-9234-00d6461e02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "SCOPUS_FILE = \"2108_Scopus Results_August 2025.xlsx\"\n",
    "WOS_FILE    = \"2508_WoS Results_August 2025.xlsx\"\n",
    "YEAR_MIN, YEAR_MAX = 0, 2025\n",
    "\n",
    "STAMP = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "OUTPUT_XLSX = f\"SLR_WoS_Scopus_{STAMP}.xlsx\"\n",
    "\n",
    "SCOPUS_COL_MAP = {\n",
    "    \"Title\": \"Title\",\n",
    "    \"Authors\": \"Authors\",\n",
    "    \"Year\": \"Year\",\n",
    "    \"Source title\": \"Source title\",\n",
    "    \"Cited by\": \"Cited by\",\n",
    "    \"DOI\": \"DOI\",\n",
    "    \"Link\": \"Link\",\n",
    "    \"Abstract\": \"Abstract\",\n",
    "    \"Author Keywords\": \"Author Keywords\",\n",
    "    \"Index Keywords\": \"Index Keywords\",\n",
    "    \"Document Type\": \"Document Type\",\n",
    "}\n",
    "WOS_COL_MAP = {\n",
    "    \"Article Title\": \"Title\",\n",
    "    \"Authors\": \"Authors\",\n",
    "    \"Publication Year\": \"Year\",\n",
    "    \"Source Title\": \"Source title\",\n",
    "    \"Times Cited, All Databases\": \"Cited by\",\n",
    "    \"DOI\": \"DOI\",\n",
    "    \"DOI Link\": \"Link\",\n",
    "    \"Abstract\": \"Abstract\",\n",
    "    \"Author Keywords\": \"Author Keywords\",\n",
    "    \"Keywords Plus\": \"Index Keywords\",\n",
    "    \"Document Type\": \"Document Type\",\n",
    "}\n",
    "\n",
    "EXPECTED_COLS = [\n",
    "    \"Title\",\"Authors\",\"Year\",\"Source title\",\"Cited by\",\"DOI\",\"Link\",\n",
    "    \"Abstract\",\"Author Keywords\",\"Index Keywords\",\"Keywords\",\"Database\",\"Document Type\"\n",
    "]\n",
    "\n",
    "def _ensure_columns(df, expected):\n",
    "    for c in expected:\n",
    "        if c not in df.columns:\n",
    "            df[c] = \"\"\n",
    "    return df[expected].copy()\n",
    "\n",
    "def load_scopus(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_excel(path, engine=\"openpyxl\")\n",
    "    df = df.rename(columns=SCOPUS_COL_MAP)\n",
    "\n",
    "    ak = df.get(\"Author Keywords\", pd.Series(\"\", index=df.index)).fillna(\"\")\n",
    "    ik = df.get(\"Index Keywords\", pd.Series(\"\", index=df.index)).fillna(\"\")\n",
    "    df[\"Keywords\"] = (ak + \"; \" + ik).str.strip(\"; \")\n",
    "\n",
    "    df[\"Year\"] = pd.to_numeric(df.get(\"Year\"), errors=\"coerce\")\n",
    "    df[\"Cited by\"] = pd.to_numeric(df.get(\"Cited by\"), errors=\"coerce\").fillna(0)\n",
    "    df = df[(df[\"Year\"].isna()) | ((df[\"Year\"] >= YEAR_MIN) & (df[\"Year\"] <= YEAR_MAX))]\n",
    "\n",
    "    if \"Language of Original Document\" in df.columns:\n",
    "        df = df[df[\"Language of Original Document\"].astype(str).str.lower().eq(\"english\")]\n",
    "\n",
    "    df[\"Link\"] = df.get(\"Link\", \"\")\n",
    "    has_no_link = df[\"Link\"].astype(str).str.strip().eq(\"\")\n",
    "    has_doi = df[\"DOI\"].astype(str).str.strip().ne(\"\")\n",
    "    df.loc[has_no_link & has_doi, \"Link\"] = \"https://doi.org/\" + df.loc[has_no_link & has_doi, \"DOI\"].astype(str)\n",
    "\n",
    "    df[\"Database\"] = \"Scopus\"\n",
    "    return _ensure_columns(df, EXPECTED_COLS)\n",
    "\n",
    "def load_wos(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_excel(path, engine=\"openpyxl\")\n",
    "    df = df.rename(columns=WOS_COL_MAP)\n",
    "\n",
    "    ak = df.get(\"Author Keywords\", pd.Series(\"\", index=df.index)).fillna(\"\")\n",
    "    ik = df.get(\"Index Keywords\", pd.Series(\"\", index=df.index)).fillna(\"\")\n",
    "    df[\"Keywords\"] = (ak + \"; \" + ik).str.strip(\"; \")\n",
    "\n",
    "    df[\"Year\"] = pd.to_numeric(df.get(\"Year\"), errors=\"coerce\")\n",
    "    df[\"Cited by\"] = pd.to_numeric(df.get(\"Cited by\"), errors=\"coerce\").fillna(0)\n",
    "    df = df[(df[\"Year\"].isna()) | ((df[\"Year\"] >= YEAR_MIN) & (df[\"Year\"] <= YEAR_MAX))]\n",
    "\n",
    "    if \"Language\" in df.columns:\n",
    "        df = df[df[\"Language\"].astype(str).str.lower().eq(\"english\")]\n",
    "\n",
    "    df[\"Link\"] = df.get(\"Link\", \"\")\n",
    "    has_no_link = df[\"Link\"].astype(str).str.strip().eq(\"\")\n",
    "    has_doi = df[\"DOI\"].astype(str).str.strip().ne(\"\")\n",
    "    df.loc[has_no_link & has_doi, \"Link\"] = \"https://doi.org/\" + df.loc[has_no_link & has_doi, \"DOI\"].astype(str)\n",
    "\n",
    "    df[\"Database\"] = \"WoS\"\n",
    "    return _ensure_columns(df, EXPECTED_COLS)\n",
    "\n",
    "def deduplicate_doi(df):\n",
    "    n0 = len(df)\n",
    "    x = df.copy()\n",
    "    x[\"__doi_norm\"] = x[\"DOI\"].astype(str).str.strip().str.lower()\n",
    "    x[\"__abs_len\"] = x[\"Abstract\"].astype(str).str.len()\n",
    "    x[\"__has_link\"] = (x[\"Link\"].astype(str).str.len() > 0).astype(int)\n",
    "\n",
    "    with_doi = x[x[\"__doi_norm\"].ne(\"\")].sort_values(\n",
    "        by=[\"__doi_norm\",\"__abs_len\",\"__has_link\"],\n",
    "        ascending=[True, False, False]\n",
    "    ).drop_duplicates(subset=\"__doi_norm\", keep=\"first\")\n",
    "\n",
    "    without_doi = x[x[\"__doi_norm\"].eq(\"\")]\n",
    "    out = pd.concat([with_doi, without_doi], ignore_index=True)\n",
    "    out = out.drop(columns=[\"__doi_norm\",\"__abs_len\",\"__has_link\"])\n",
    "    return out, {\"initial\": n0, \"after\": len(out), \"removed\": n0 - len(out)}\n",
    "\n",
    "KEEP_TYPES = [\n",
    "    \"Article\", \"Review\",\n",
    "    \"Article; Data Paper\", \"Data paper\",\n",
    "    \"Article; Book Chapter\", \"Book chapter\",\n",
    "    \"Article; Early Access\",\n",
    "    \"Conference paper\"\n",
    "]\n",
    "\n",
    "ACCESS_TERMS = [\n",
    "    r\"\\belectricity\\b\",\n",
    "    r\"\\belectricity access\\b\",\n",
    "    r\"\\benergy access\\b\",\n",
    "    r\"\\belectrification\\b\",\n",
    "    r\"\\belectrification (?:access|rate|level|coverage|mapping|measurement|progress)\\b\"\n",
    "]\n",
    "CORE_TERMS = [\n",
    "    r\"\\bmeasur\\w*\\b\", \n",
    "    r\"\\bestimat\\w*\\b\", \n",
    "    r\"\\bmap\\w*\\b\", \n",
    "    r\"\\bdefin\\w*\\b\",\n",
    "    r\"\\btrack\\w*\\b\", \n",
    "    r\"\\bsdg tracking\\b\", r\"\\btracking sdg ?7\\b\", \"Sustainable Development Goal 7\"\n",
    "r\"monitor\\w*(?:\\W+\\w+){0,5}\\s+(?:electrification|electricit(?:y)?|energy\\s+access)\"\n",
    "]\n",
    "METHOD_TERMS = [\n",
    "    # Surveys\n",
    "    \"multi-tier framework\", \"mtf\", \"world bank\",\n",
    "    \"demographic and health survey\", \"dhs\",\n",
    "    \"living standards measurement study\", \"lsms\",\n",
    "    \"multiple indicator cluster survey\", \"mics\",\n",
    "    \"world health survey\", \"whs\",\n",
    "    \"study on global ageing and adult health\", \"sage\",\n",
    "    \"household survey\", \"census\", \"censal\",\n",
    "\n",
    "    # Remote sensing / geospatial\n",
    "    \"nighttime light\", \"night-time light\", \"night time light\",\n",
    "    \"Visible Infrared Imaging Radiometer Suite\", \"viirs\", \"Defense Meteorological Satellite Program\", \"dmsp\", \n",
    "    \"remote sensing\", \"geospatial\", \"spatial\",\n",
    "    \"satellite data\", \"satellite imagery\",\n",
    "\n",
    "    # Mobile data\n",
    "    \"mobile phone data\", \"call detail record\", \"cdr\",\n",
    "\n",
    "    # Solar/off-grid\n",
    "\n",
    "    r\"\\bsolar home systems?\\b\",\n",
    "    r\"\\bshs\\b\",\n",
    "    r\"\\bsolar (?:pv?s?|photovoltaics?|power|generation|electrification)\\b\",\n",
    "    r\"\\boff[ -]?grid(?: solar)?\\b\"\n",
    "    \n",
    "]\n",
    "\n",
    "EXCLUDE_TERMS = [\"lightning\",\"thunderstorm\",\"volcan\",\"weather radar\",\"precipitation\",\"atmospher\", \"weather\", \"weather conditions\",\n",
    "                \"optimisation\",\"optimization\",\"techno[- ]?economic\",\"levelized cost of electricity\", \"lcoe\", \"net present value\", \"npv\",\"payback\",\"homer\",\"sizing\",\"cost-?benefit\",\n",
    "                 \"battery\", \"batteries\", \"electric vehicle\", \"transport\", \"transfer\",\n",
    "                 \"smart grid\", \"pollution\"\n",
    "]\n",
    "\n",
    "VALIDATION_TERMS = [\n",
    "    r\"\\bvalidat\\w*\\b\",       \n",
    "    r\"\\bcompar(?:e|es|ed|ing|ison|isons)\\b\"\n",
    "]\n",
    "\n",
    "\n",
    "def screen_keywords_simple(df):\n",
    "    texts = (df[\"Title\"].fillna(\"\") + \" \" + df[\"Keywords\"].fillna(\"\")).str.lower()\n",
    "\n",
    "    hit_access   = texts.str.contains(\"|\".join(ACCESS_TERMS),     regex=True)\n",
    "    hit_core     = texts.str.contains(\"|\".join(CORE_TERMS),       regex=True)\n",
    "    hit_method   = texts.str.contains(\"|\".join(METHOD_TERMS),     regex=True)\n",
    "    hit_excl     = texts.str.contains(\"|\".join(EXCLUDE_TERMS),    regex=True)\n",
    "    hit_validate = texts.str.contains(\"|\".join(VALIDATION_TERMS), regex=True)\n",
    "\n",
    "    kw_pass = hit_access & (hit_core | hit_method) & ~hit_excl\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"hit_access\"]   = hit_access\n",
    "    out[\"hit_core\"]     = hit_core\n",
    "    out[\"hit_method\"]   = hit_method\n",
    "    out[\"hit_excl\"]     = hit_excl\n",
    "    out[\"hit_validate\"] = hit_validate\n",
    "    out[\"kw_pass\"]      = kw_pass\n",
    "    out[\"kw_fail\"]      = ~kw_pass\n",
    "    out[\"kw_reason\"]    = np.where(kw_pass, \"rule_access_coreOrMethod\", \"fail\")\n",
    "\n",
    "    out[\"proceed to abstract check\"] = np.where(out[\"kw_pass\"] & out[\"hit_validate\"], \"yes\", \"\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "df_scopus = load_scopus(SCOPUS_FILE)\n",
    "df_wos = load_wos(WOS_FILE)\n",
    "\n",
    "df_all = pd.concat([df_scopus, df_wos], ignore_index=True)\n",
    "raw_total = len(df_all)\n",
    "print(f\"[0] Raw merged total: {raw_total}\")\n",
    "\n",
    "df_all = df_all[df_all[\"Document Type\"].isin(KEEP_TYPES)]\n",
    "after_doctype = len(df_all)\n",
    "print(f\"[1] After doc-type filter: {after_doctype} (removed {raw_total - after_doctype})\")\n",
    "\n",
    "df_dedup, stats = deduplicate_doi(df_all)\n",
    "print(f\"[2] Dedup: {stats}\")\n",
    "\n",
    "df_kw = screen_keywords_simple(df_dedup)\n",
    "df_pass = df_kw[df_kw[\"kw_pass\"]].copy()\n",
    "df_fail = df_kw[~df_kw[\"kw_pass\"]].copy()\n",
    "print(f\"[3] Keyword screening -> Pass: {len(df_pass)} | Fail: {len(df_fail)}\")\n",
    "\n",
    "txt_pass = (df_pass[\"Title\"].fillna(\"\") + \" \" +\n",
    "            df_pass[\"Abstract\"].fillna(\"\") + \" \" +\n",
    "            df_pass[\"Keywords\"].fillna(\"\")).str.lower()\n",
    "\n",
    "prox_patterns = [\n",
    "    r\"(?:measur\\w*|estimat\\w*|map\\w*|defin\\w*|validat\\w*|metric|indicator|index|tracking?)\"\n",
    "    r\"(?:\\W+\\w+){0,8}\\b(?:electrification|electricity access|energy access)\\b\",\n",
    "    r\"\\b(?:electrification|electricity access|energy access)\\b\"\n",
    "    r\"(?:\\W+\\w+){0,8}(?:measur\\w*|estimat\\w*|map\\w*|defin\\w*|validat\\w*|metric|indicator|index|tracking?)\"\n",
    "]\n",
    "design_rx = r\"\\b(?:optimization|optimisation|feasibility|sizing|homer|lcoe|npv|payback|economic analysis|techno[- ]?economic)\\b\"\n",
    "survey_rx = r\"\\b(?:household survey|dhs|lsms|mics|census|national survey|multi[- ]tier framework|mtf)\\b\"\n",
    "rs_rx     = r\"\\b(?:night[ -]?time light|viirs|dmsp|remote sensing|satellite|geospatial|high resolution imagery)\\b\"\n",
    "\n",
    "df_pass[\"hit_prox8\"]   = txt_pass.str.contains(\"|\".join(prox_patterns), regex=True)\n",
    "df_pass[\"design_lang\"] = txt_pass.str.contains(design_rx, regex=True)\n",
    "df_pass[\"survey_hits\"] = txt_pass.str.count(survey_rx)\n",
    "df_pass[\"rs_hits\"]     = txt_pass.str.count(rs_rx)\n",
    "df_pass[\"abstract_len\"]= df_pass[\"Abstract\"].fillna(\"\").str.len()\n",
    "\n",
    "year  = pd.to_numeric(df_pass[\"Year\"], errors=\"coerce\").fillna(0)\n",
    "cites = pd.to_numeric(df_pass[\"Cited by\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "def suggest_decision(row):\n",
    "    if row[\"hit_prox8\"] and (row[\"survey_hits\"] > 0 or row[\"rs_hits\"] > 0):\n",
    "        return \"include\"\n",
    "    if row[\"design_lang\"] and not row[\"hit_prox8\"]:\n",
    "        return \"exclude\"\n",
    "    if row[\"abstract_len\"] < 250:\n",
    "        return \"exclude\"\n",
    "    return \"maybe\"\n",
    "\n",
    "df_pass[\"abstract_decision\"] = df_pass.apply(suggest_decision, axis=1)\n",
    "df_pass[\"abstract_notes\"]    = \"\"\n",
    "\n",
    "print(\"[4] Auto-suggested decisions assigned.\")\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\") as w:\n",
    "    df_all.to_excel(w, sheet_name=\"0_Raw_Merged\", index=False)\n",
    "    df_dedup.to_excel(w, sheet_name=\"1_Deduplicated\", index=False)\n",
    "    df_kw.to_excel(w, sheet_name=\"2_KeywordScreen_All\", index=False)\n",
    "    df_pass.to_excel(w, sheet_name=\"2a_Keyword_PASS\", index=False)\n",
    "    df_fail.to_excel(w, sheet_name=\"2b_Keyword_FAIL\", index=False)\n",
    "\n",
    "print(f\"Done. Saved {OUTPUT_XLSX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dfbf27-33bc-4ec2-ad5d-fcad5cd43cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "OLD_FILE  = \"2608_Dissertation_Systematic Literature Review_v2.xlsx\"\n",
    "OLD_SHEET = \"WOS+Scop\"\n",
    "CUR_SHEET = \"2a_Keyword_PASS\"\n",
    "\n",
    "MANUAL_COLS = [\n",
    "    \"Include (Yes/No)\",\n",
    "    \"Inclusion reason (initial screening)\",\n",
    "    \"Exclusion Reason\",\n",
    "    \"Ground Truth Mentioned (Yes/No/Maybe)\",\n",
    "    \"Second check - Relevance of abstract (Yes/No)\",\n",
    "    \"Methodology Type\",\n",
    "    \"Validation Strategy\",\n",
    "    \"Region/Country\",\n",
    "    \"Notes\",\n",
    "    \"Highly relevant (Yes/No)\",\n",
    "    \"Abstract excerpts\",\n",
    "]\n",
    "\n",
    "curr = pd.read_excel(OUTPUT_XLSX, sheet_name=CUR_SHEET, engine=\"openpyxl\").copy()\n",
    "curr[\"DOI_norm\"]   = curr[\"DOI\"].astype(str).str.strip().str.lower()\n",
    "curr[\"Title_norm\"] = curr[\"Title\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "old = pd.read_excel(OLD_FILE, sheet_name=OLD_SHEET, engine=\"openpyxl\").copy()\n",
    "old[\"DOI_norm\"]   = old[\"DOI\"].astype(str).str.strip().str.lower()\n",
    "old[\"Title_norm\"] = old[\"Title\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "for c in MANUAL_COLS:\n",
    "    if c not in old.columns:\n",
    "        old[c] = \"\"\n",
    "\n",
    "manual = old[[\"DOI_norm\",\"Title_norm\"] + MANUAL_COLS].copy()\n",
    "\n",
    "by_doi   = manual.dropna(subset=[\"DOI_norm\"]).drop_duplicates(\"DOI_norm\").set_index(\"DOI_norm\")\n",
    "by_title = manual.dropna(subset=[\"Title_norm\"]).drop_duplicates(\"Title_norm\").set_index(\"Title_norm\")\n",
    "\n",
    "for c in MANUAL_COLS:\n",
    "    curr[c] = curr[\"DOI_norm\"].map(by_doi[c])  # DOI match\n",
    "    mask = curr[c].isna() & curr[\"Title_norm\"].notna()\n",
    "    curr.loc[mask, c] = curr.loc[mask, \"Title_norm\"].map(by_title[c])  # Title fallback\n",
    "    curr[c] = curr[c].fillna(\"\")\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as w:\n",
    "    curr.drop(columns=[\"DOI_norm\",\"Title_norm\"], errors=\"ignore\").to_excel(w, sheet_name=CUR_SHEET, index=False)\n",
    "\n",
    "wb = load_workbook(OUTPUT_XLSX)\n",
    "ws = wb[CUR_SHEET]\n",
    "header_cells = {cell.value: cell for cell in next(ws.iter_rows(min_row=1, max_row=1))}\n",
    "yellow = PatternFill(start_color=\"FFFF99\", end_color=\"FFFF99\", fill_type=\"solid\")\n",
    "for col_name in MANUAL_COLS:\n",
    "    cell = header_cells.get(col_name)\n",
    "    if cell:\n",
    "        cell.fill = yellow\n",
    "wb.save(OUTPUT_XLSX)\n",
    "\n",
    "print(\"Manual-screening columns merged and highlighted in 2a_Keyword_PASS.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a15d6-502a-45b7-b38b-3c2e052161b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "must_appear_dois = [\n",
    "    \"10.1038/s41597-019-0122-6\",        # Falchetta 2019\n",
    "    \"10.1140/epjds/s13688-022-00371-5\", # Pokhriyal 2022\n",
    "    \"10.1109/powerafrica57932.2023.10363249\", # Temesgen 2023\n",
    "    \"10.1016/j.rse.2019.111430\",        # Stokes & Seto 2019\n",
    "    \"10.1007/s41324-019-00307-8\",       # Paul 2020\n",
    "    \"10.1109/jstars.2023.3316310\",      # He 2023\n",
    "    \"10.1080/01431161.2017.1420936\",    # Dugoua 2018\n",
    "    \"10.1016/j.oneear.2020.03.007\",     # Falchetta 2020\n",
    "    \"10.1080/19376812.2021.1897023\",    # Dlamini 2022\n",
    "    \"10.1145/3447555.3464871\",          # Correa 2021\n",
    "    \"10.3390/ijgi11040222\",             # Ren 2022\n",
    "    \"10.1002/9780470979563.ch15\",       # Elvidge 2011 (book chapter)\n",
    "    \"10.1016/j.joule.2024.05.001\"       # Manual entry 2024\n",
    "]\n",
    "\n",
    "import re\n",
    "def normalize_doi(x: str) -> str:\n",
    "    s = str(x or \"\").strip().lower()\n",
    "    # strip common prefixes\n",
    "    s = re.sub(r\"^(https?://(dx\\.)?doi\\.org/|doi:\\s*)\", \"\", s)\n",
    "    return s\n",
    "\n",
    "df_kw = df_kw.copy()\n",
    "df_kw.loc[:, \"DOI_norm\"] = df_kw[\"DOI\"].apply(normalize_doi)\n",
    "\n",
    "passes = df_kw[df_kw[\"kw_pass\"]].copy()\n",
    "\n",
    "must_norm = {normalize_doi(d) for d in must_appear_dois if d}\n",
    "\n",
    "present_norm = set(passes[\"DOI_norm\"].dropna().tolist())\n",
    "missing = sorted(must_norm - present_norm)\n",
    "\n",
    "if missing:\n",
    "    print(\"These must-appear DOIs are missing after filters:\", missing)\n",
    "else:\n",
    "    print(\"All must-appear DOIs survived the filters!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4827df-df47-4b0d-aa7e-e3739b227fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = df_fail[df_fail[\"DOI\"].astype(str).str.lower().isin([d.lower() for d in must_appear_dois])]\n",
    "print(\"Must-appear DOIs excluded:\", excluded[\"DOI\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b6f4a-7809-4c94-b2f0-e4e2bea2efe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ce256-d46c-4a91-84df-e8e149a0b8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
